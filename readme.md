# Fundamentals of AI/ML and Applications 
Sponsored by **Software Technology Parks of India (STPI)**


Welcome to the training website!

## Course Content
This is an introductory course to machine learning for STPI participants with some background in calculus, linear algebra, and statistics. The course focuses on supervised learning, i.e., classification and regression. The course will cover a range of methods used in machine learning and data science, including:
- Linear regression
- Classification via logistic regression
- Decision trees
- Neural networks (ANN, CNN, RNN)
- k-means clustering
- Ensemble methods

Heavy focus will be placed on understanding fundamental algorithms for ML.
The course includes theory and case studies. 

**Note**: Participants must have wifi access and a Google account to work with Google Colab.

<br> <br>
**Instructors:** 
* Rajdip Nayek [RN] (rajdipn@am.iitd.ac.in) 
* Rushdie Islam [RI] (rushdie@am.iitd.ac.in)                 

<br> <br>
**Venue:** IIT Delhi, LHC 212 (Conference Room)
<br> <br>

**Participants:** <br>

[Link here](https://docs.google.com/spreadsheets/d/1xkLnCM9qTsG5AlYkEy6qsFLdM_OUc5ae3enXBp5fuII/edit?usp=sharing)

<br> <br>
**Schedule:**
![image](https://github.com/user-attachments/assets/3d7bc10c-f0fc-47a7-a265-19c8e36adefe)


<br> <br>
# Lectures

|Instructor| Topic | Lecture Notes | 
|:----------:|:------------------------------:|:------------------:|
|SC (yellow) | Introduction to AI/ML | [Lecture](Lectures/Lecture-1_cris.pdf) | 
|RN (blue) | Python and NumPy Crash Course | [NumPy](https://colab.research.google.com/drive/1MvKS3JogqtJHrBfzyFMOcOa0eVskMB4S#scrollTo=el7ocr07qte-) | 
|SC (yellow) | Linear Regression <br> Logistic Regression | [Lecture](Lectures/Lecture-3_cris.pdf) | 
|RN (blue) | Pandas and Matplotlib Crash Course| [Pandas_Matplotlib](https://colab.research.google.com/drive/1sl88MXV_6cictN1vaSEd6J_82swB9zYt)|
|RN (blue) | Data Wrangling/ Understanding your data <br> Prepare Data for ML  |  [Data_Wrangling](https://colab.research.google.com/drive/1QW4Gk6VcPnlSVXfMvwMTcI3OCNzmRQlC) <br> [Prepare_Data](https://colab.research.google.com/drive/19SYTvWptUBR4w7mKayzjJ1wtfTfLQpPY?usp=sharing) | 
|RN (blue) | Linear Regression from Scratch & Sklearn <br> Linear Regression with PyTorch | [LinReg_Scratch](https://colab.research.google.com/drive/1OhVXsRUei6B_TLAoV84WuZ0yVIZDi1sH?usp=sharing), [LinReg_Scratch_sol](https://colab.research.google.com/drive/1s98smWAdOY0RFAMRgZRnT2y-9q0BIDDx?usp=sharing) <br> [LinReg_PyTorch](https://colab.research.google.com/drive/1POGb8tZGDawVLZTfoPUitchtVpxvFwgg?usp=sharing)|
|SC (yellow) | Artificial Neural Networks (ANN)| [ANN notes](https://csciitd-my.sharepoint.com/:p:/g/personal/souvik_iitd_ac_in/EYUdDY0-uH5MnUitD53gZVsB-U2AiRC1WQDJzRSmxQ3XUw?e=wiTLNm) |
|SC (yellow)| Introduction to PyTorch  | [Intro2PyTorch](https://colab.research.google.com/drive/1Bdp9V8ij5d05ayqqiAZ2gS7ZklhNaVVu?usp=sharing),  [Files](https://drive.google.com/drive/folders/1GNu-CsZp4jKPHGFHtkMne3FuDfDEzjrv)| 
|SC (yellow)| ANN with PyTorch  |[ANN w PyTorch](https://colab.research.google.com/drive/1TjU4ethtTMJoWTIoRMrVS3uRYgdqdhq2?usp=sharing) <br> [Practice 1](https://colab.research.google.com/drive/1JxyLjdVWHLEOhj5K56e9oaqOILmLczrO?usp=sharing), [Practice 1 sol](https://colab.research.google.com/drive/1pZI_TC-29z6QzDtDfJhKT_xsAenzTbuE?usp=sharing)|
|RN (blue) | Logistic Regression with Scikit | [LogReg](https://colab.research.google.com/drive/1sVmOl3VjgVEsK8JT_zA4IUBh695E4qsl?usp=sharing) |
|RN (blue) | Performance Evaluation Metrics |[Eval_metrics](https://colab.research.google.com/drive/1LK62xrDBv8MaATYxLms-_rZilR5XJ7qt?usp=sharing) |
|RN (blue) | Support Vector Machine | [SVM](https://colab.research.google.com/drive/1nn2uYXMzVHWEKHMEFqds-XKFyXNPOYBk?usp=sharing) | 
|SC (yellow)| Convolutional Neural Networks (CNN) | [CNN notes](https://csciitd-my.sharepoint.com/:p:/g/personal/souvik_iitd_ac_in/EcdPC_Pmf8dJqomRAKMeXtwBANfHNox9sXYC1kv-0SlwaQ?e=FjZgVQ) |
|SC (yellow)| CNN (Practical) | [CNN](https://colab.research.google.com/drive/1GF9bKOMGxWP6p7ELI1XYAOY2PtZfTl2o?usp=sharing), [CNN Network](https://colab.research.google.com/drive/1NFQKp0W_blRMD9GPU3C3KucIMVfFvRpc?usp=sharing), <br> [CNN_FM](https://colab.research.google.com/drive/1Lmz1eVtGgWFxF0c6nzBnetgAxrvhfWG-?usp=sharing), [Data](https://drive.google.com/drive/folders/1IKzr2Rit9nsmv07rFKTM1_ER5qyq9V7X?usp=sharing) |
|RN (blue) | Decision Trees | [Decision Trees](https://colab.research.google.com/drive/12KpMnlZsoteBc5ExGG35I2YWv5FfjCpv?usp=sharing) |
|SC (yellow) | Recurrent Neural Networks | [L1](Lectures/RNN.pdf), [L2](Lectures/RNN2.pdf) | 
|SC (yellow)| RNN (Practical) | [RNN Practical](https://colab.research.google.com/drive/17eq3gOED9ynqc0_aeWICdJ_VtJyaxWFF?usp=sharing)|
|RN (blue) | TensorFlow Runthrough | [NN w TensorFlow 1](https://colab.research.google.com/drive/1WDbMHWRRd6ejILj4YvTG3RMHgc-q2QeU?usp=sharing) <br> [NN w TensorFlow 2](https://colab.research.google.com/drive/11sHp_WrlRSnkig1JzszwKbbXhQ0dDWP3?usp=sharing) |
|SC (yellow)| Unsupervised Learning | [Notes](Lectures/USL.pdf)|
|SC (yellow)| PCA (Practical) | [PCA Practice](https://colab.research.google.com/github/redwankarimsony/PCA-from-Scratch-in-Python/blob/main/PCA_with_MNIST_Dataset.ipynb), [Data](https://drive.google.com/drive/folders/1eP6NPdwV5MYJY9xkjxo1tW024FodRU0X?usp=sharing)|
|SC (yellow)| K-means clustering | [KMeans](https://colab.research.google.com/drive/1B0wLi7ejfaKGr0QiuCFFUqq8e1udG5e5?usp=sharing)|
|RN (blue) | KMeans Clustering (with Sklearn) | [KMeans_sklearn](https://colab.research.google.com/drive/1naGl6oFhWhpvv5c0ManJdHmQcKFcoGgR?usp=sharing)|
|RN (blue) | Random Forests |[Random Forests](https://colab.research.google.com/drive/1BpZ3QEbbT8od9lbjEvhF9T7zAvFKy4Q8?usp=sharing) |
|RN (blue) | Save and Load Models | [Save Models](https://colab.research.google.com/drive/1WodtWy_jgKeP2Sr1DJ9ovnvrtzOC-ZRq?usp=sharing) | 
|RN (blue) | User Aspects of ML | [User Practices](Lectures/UserAspectsML.pdf)|

<br> <br>

# Some Course Lectures Material (by RN)

| Topic | Lecture Notes | 
|:--------------------------:|:------------------:|
| Introduction to AI/ML | [L1](Lectures/Intro2ML.pdf) | 
| Introduction to Supervised Learning | [L2](Lectures/Intro2Supervised.pdf)|
| k-Nearest Neighbours |  [L3](Lectures/kNN.pdf) | 
| Decision Trees (CART) | [L4](Lectures/DecisionTrees.pdf)|
| Linear Regression | [L5](Lectures/LinearRegression.pdf)|
| Logistic Regression | [L6](Lectures/LogisticRegression.pdf)|
| Optimization | [L7](Lectures/Parm_Opt.pdf) |
| Support Vector Machine| [L8](https://github.com/coursesAM/APL405W24/blob/6196cdf0a18eccf77b53ee45dfd6b3618ceba7fb/Lectures/Lecture18.pdf) |
| Ensemble Methods | [L9](Lectures/Ensembles.pdf) |
| Random Forests | [L10](Lectures/RF.pdf) |


<br> <br>

## Course References
* [AL] Andreas Lindholm et. al., *"Machine Learning: A First Course for Engineers and Scientists"*, Cambridge University Press, 2022 [[free pdf](http://smlbook.org/book/sml-book-draft-latest.pdf)]
* Andriy Burkov, *"The Hundred Page Machine Learning Book"*, 2019 [[free pdf](http://ema.cri-info.cm/wp-content/uploads/2019/07/2019BurkovTheHundred-pageMachineLearning.pdf)].
* Jake VanderPlas, *"Python Data Science Handbook"*, 2016 [[Book website](https://jakevdp.github.io/PythonDataScienceHandbook/index.html)].

<br> <br>

## Grading  
Assessment will be done using marks obtained in practicals.

Please take this [QUIZ](https://docs.google.com/forms/d/e/1FAIpQLSdv2T8HOpzwKQjwy6qjEEFYT0FRDVBE-5ns2en2352BHvXwsg/viewform?usp=sf_link)

